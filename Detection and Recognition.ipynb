{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "230cb74e",
   "metadata": {},
   "source": [
    "# Import necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a66e8a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import easyocr\n",
    "from ultralytics import YOLO\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8a1ebc",
   "metadata": {},
   "source": [
    "# License Plate Detection only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d82c954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Processed 631 frames\n",
      "[INFO] Total Time: 56.46s\n",
      "[INFO] Average FPS (GPU): 11.18\n"
     ]
    }
   ],
   "source": [
    "# Load the YOLO model\n",
    "\n",
    "# model = YOLO(\"best_model_yolo11s.onnx\")\n",
    "model = YOLO(\"best_model_yolo11s.pt\")\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"demo.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Set the device for inference\n",
    "use_gpu = True  # Set to True to use GPU, False for CPU\n",
    "\n",
    "if use_gpu:\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "\n",
    "frame_count = 0\n",
    "total_time = 0.0\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Run YOLO inference on the frame\n",
    "        results = model(frame, device=device, verbose=False)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        total_time += elapsed\n",
    "        frame_count += 1\n",
    "\n",
    "        fps = 1.0 / elapsed\n",
    "        cv2.putText(annotated_frame, f\"FPS: {fps:.2f}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLO Inference\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "avg_fps = frame_count / total_time if total_time > 0 else 0\n",
    "print(f\"\\n[INFO] Processed {frame_count} frames\")\n",
    "print(f\"[INFO] Total Time: {total_time:.2f}s\")\n",
    "print(f\"[INFO] Average FPS ({'GPU' if use_gpu else 'CPU'}): {avg_fps:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60370eb0",
   "metadata": {},
   "source": [
    "# License Plate Detection & Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fbfe015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Transformation module specified\n",
      "\n",
      "[INFO] Processed 631 frames\n",
      "[INFO] Total Time: 552.93s\n",
      "[INFO] Average FPS (CPU): 1.14\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "use_gpu = False\n",
    "\n",
    "## Initialize OCR reader once (Default language is English)\n",
    "# reader = easyocr.Reader(['en'], gpu=use_gpu)\n",
    "\n",
    "# Custom recognition model path\n",
    "reader = easyocr.Reader(['en'], gpu=use_gpu, recog_network='num_plate_ocr')\n",
    "PREDICTION_ALLOW_LIST = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ.-'\n",
    "\n",
    "def get_ocr(im, box):\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    cropped = im[y1:y2, x1:x2]\n",
    "    gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    results = reader.readtext(gray, allowlist=PREDICTION_ALLOW_LIST)\n",
    "    for result in results:\n",
    "        text, score = result[1], result[2]\n",
    "        if score > 0.2:\n",
    "            return text\n",
    "    return \"\"\n",
    "\n",
    "def draw_boxes_with_ocr(image, boxes, confidences, classes, names):\n",
    "    for box, conf, cls in zip(boxes, confidences, classes):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        label = f\"{names[int(cls)]} {conf:.2f}\"\n",
    "        ocr_text = get_ocr(image, (x1, y1, x2, y2))\n",
    "        label = ocr_text if ocr_text else label\n",
    "\n",
    "        color = (0, 255, 0)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    return image\n",
    "\n",
    "def run_video_prediction(model_path=\"best_model_yolo11s.pt\", source=0, use_gpu=True):\n",
    "    device = 'cuda' if use_gpu else 'cpu'\n",
    "    model = YOLO(model_path)\n",
    "    cap = cv2.VideoCapture(source)\n",
    "\n",
    "    frame_count = 0\n",
    "    total_time = 0.0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        results = model.predict(frame, device=device, verbose=False)[0]\n",
    "        names = model.names\n",
    "\n",
    "        boxes = results.boxes.xyxy.cpu().numpy()\n",
    "        confs = results.boxes.conf.cpu().numpy()\n",
    "        classes = results.boxes.cls.cpu().numpy()\n",
    "\n",
    "        frame = draw_boxes_with_ocr(frame, boxes, confs, classes, names)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed = end_time - start_time\n",
    "        total_time += elapsed\n",
    "        frame_count += 1\n",
    "\n",
    "        fps = 1.0 / elapsed\n",
    "        cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"License Plate Recognition\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    avg_fps = frame_count / total_time if total_time > 0 else 0\n",
    "    print(f\"\\n[INFO] Processed {frame_count} frames\")\n",
    "    print(f\"[INFO] Total Time: {total_time:.2f}s\")\n",
    "    print(f\"[INFO] Average FPS ({'GPU' if use_gpu else 'CPU'}): {avg_fps:.2f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_video_prediction(\"best_model_yolo11s.pt\", source=\"demo.mp4\", use_gpu=use_gpu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82beb05",
   "metadata": {},
   "source": [
    "# Custom Recognition Model Placing in ~/.EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc6e492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Custom model files copied to EasyOCR directories.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "custom_model_name = \"num_plate_ocr\"\n",
    "\n",
    "yaml_src = r\"G:\\My Documents\\Digital Neuron Labtech\\Project Src\\Recognition Model\\num_plate_ocr.yaml\"\n",
    "py_src = r\"G:\\My Documents\\Digital Neuron Labtech\\Project Src\\Recognition Model\\num_plate_ocr.py\"\n",
    "pth_src = r\"G:\\My Documents\\Digital Neuron Labtech\\Project Src\\Recognition Model\\num_plate_ocr.pth\"\n",
    "\n",
    "# Destinations (EasyOCR looks here when loading custom models)\n",
    "dst_yaml = os.path.expanduser(f\"~/.EasyOCR/user_network/{custom_model_name}.yaml\")\n",
    "dst_py = os.path.expanduser(f\"~/.EasyOCR/user_network/{custom_model_name}.py\")\n",
    "dst_pth = os.path.expanduser(f\"~/.EasyOCR/model/{custom_model_name}.pth\")\n",
    "\n",
    "# Copy\n",
    "shutil.copy(yaml_src, dst_yaml)\n",
    "shutil.copy(py_src, dst_py)\n",
    "shutil.copy(pth_src, dst_pth)\n",
    "\n",
    "print(\"✅ Custom model files copied to EasyOCR directories.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
